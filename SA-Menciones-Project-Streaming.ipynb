{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://qs.topuniversities.com/hs-fs/hubfs/07_HumanScience_H_300.jpg?width=4961&height=3508&name=07_HumanScience_H_300.jpg\" width=\"250\" height=\"100\"  />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Walk The Talk || Hands-On Big Data Streaming using Apache Spark \n",
    "## Real-Time Analysis of Your Political Standing\n",
    "### Group F\n",
    "#### Nicolas Fraire, Camille Eloi, Iñigo Hidalgo, Dea Markovic, Harshil Sharma, Oriol Vila, Gerardo Gandara\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://drive.google.com/file/d/1aMOA01zk4bPDQF32vH2UG2X44gDqfKZg/view?usp=sharing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the amazing frameworks that can handle big data in real-time and perform different analysis, is Apache Spark. I think there are many resources that provide information about different features of Spark and how popular it is in the big data community but shortly mentioning the core features of Spark: it does fast big data processing employing Resilient Distributed Datasets (RDDs), streaming and Machine learning on a large scale at real-time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<img src=\"https://cdn.analyticsvidhya.com/wp-content/uploads/2018/07/performing-twitter-sentiment-analysis1.jpg\" />\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install --upgrade pip\n",
    "#!pip3 install pysentimiento\n",
    "#!pip3 install torch\n",
    "#!pip3 install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pysentimiento import SentimentAnalyzer\n",
    "analyzer = SentimentAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  We are going to use findspark library to locate Spark on our local machine and then we import necessary packages from pyspark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#you need to put where is spark installed\n",
    "# with this command : echo 'sc.getConfget('spark.home')' | spark-shell\n",
    "findspark.init('/opt/spark-3.0.0-bin-hadoop3.2/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# May cause deprecation warnings, safe to ignore, they aren't errors\n",
    "from pyspark import SparkContext\n",
    "from pyspark.streaming import StreamingContext\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql.functions import desc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We initiate SparkContext(). SparkContext is the entry point to any spark functionality. When we run any Spark application, a driver program starts, which has the main function and your SparkContext gets initiated here. A SparkContext represents the connection to a Spark cluster, and can be used to create RDDs, accumulators and broadcast variables on that cluster. SparkContext here uses Py4J to launch a JVM and creates a JavaSparkContext (source). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can only run this once. restart your kernel for any errors.\n",
    "sc = SparkContext()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "it is important to note that **only one SparkContext** may be running at each session. (That is why the trial and error is time consuming when you are learning, but it is ok, it is worthy!).\n",
    "\n",
    "After that, we initiate the StreamingContext() with 10-second batch intervals, it means that the input streams will be divided into batches every 10 seconds during the streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssc = StreamingContext(sc, 10 )\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "socket_stream = ssc.socketTextStream(\"127.0.0.1\", 5555)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssc.checkpoint(\"checkpoint_TwitterApp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now, our next step is to assign our input source of streaming and then put the incoming data in variable lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "it is important to note that we are using the same port number (5555) as we used in the first module to send the tweets and the IP address (VM for our case) is the same since we are running things on our local machine. in addition\n",
    "\n",
    "**We are using the window() function to determine that we are analyzing tweets every minute (60 seconds) to see what the top 10 #mentions are during that time**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = socket_stream.window( 60 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We will create TEMP tables for each candidate/mentions and a table with TWEETS for SA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Politicians Count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Then we need to calculate how many times the Candidate has been mentioned. We can do that by using the function reduceByKey. This function will calculate how many times the candidate has been mentioned per each batch, i.e. it will reset the counts in each batch. In this version for prototype purposes we used reduceByKey but it important to emphasize the difference. We can simulate it with a loop calculation later for you to see the difference.\n",
    "\n",
    "#### In future cases, we need to calculate the counts across all the batches, so we’ll use another function called updateStateByKey, as this function allows you to maintain the state of RDD while updating it with new data. This way is called Stateful Transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just a tuple to assign names\n",
    "from collections import namedtuple\n",
    "\n",
    "fields = (\"candidato\", \"count\" )\n",
    "Candidato = namedtuple( 'Candidato', fields )\n",
    "\n",
    "# here we apply different operations on the tweets and save them to #a temporary sql table\n",
    "\n",
    "( lines.flatMap( lambda text: text.split( \" \" ) ) #Splits to a list\n",
    "  # Checks for    candidate calls  \n",
    "  .filter( lambda word: word.lower().startswith(\"ayuso\") ) \n",
    "  .map( lambda word: ( word.lower(), 1 ) ) # Lower cases the word\n",
    "  .reduceByKey( lambda a, b: a + b ) \n",
    " # Stores in a Tweet Object\n",
    "  .map( lambda rec: Candidato( rec[0], rec[1] ) )\n",
    " # Sorts Them in a dataframe\n",
    "  .foreachRDD( lambda rdd: rdd.toDF().sort( desc(\"count\") )\n",
    " # Registers only top 10 key words that starts with the candidate name to a table.\n",
    "  .limit(10).registerTempTable(\"c_ayuso\") ) )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just a tuple to assign names\n",
    "from collections import namedtuple\n",
    "\n",
    "fields = (\"candidato\", \"count\" )\n",
    "Candidato = namedtuple( 'Candidato', fields )\n",
    "\n",
    "# here we apply different operations on the tweets and save them to #a temporary sql table\n",
    "\n",
    "( lines.flatMap( lambda text: text.split( \" \" ) ) #Splits to a list\n",
    "  # Checks for    candidate calls  \n",
    "  .filter( lambda word: word.lower().startswith(\"gabilondo\") ) \n",
    "  .map( lambda word: ( word.lower(), 1 ) ) # Lower cases the word\n",
    "  .reduceByKey( lambda a, b: a + b ) \n",
    " # Stores in a Tweet Object\n",
    "  .map( lambda rec: Candidato( rec[0], rec[1] ) )\n",
    " # Sorts Them in a dataframe\n",
    "  .foreachRDD( lambda rdd: rdd.toDF().sort( desc(\"count\") )\n",
    " # Registers only top 10 candidate to a table.\n",
    "  .limit(10).registerTempTable(\"c_gabilondo\") ) )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just a tuple to assign names\n",
    "from collections import namedtuple\n",
    "\n",
    "fields = (\"candidato\", \"count\" )\n",
    "Candidato = namedtuple( 'Candidato', fields )\n",
    "\n",
    "# here we apply different operations on the tweets and save them to #a temporary sql table\n",
    "\n",
    "( lines.flatMap( lambda text: text.split( \" \" ) ) #Splits to a list\n",
    "  # Checks for    candidate calls  \n",
    "  .filter( lambda word: word.lower().startswith(\"monica\") ) \n",
    "  .map( lambda word: ( word.lower(), 1 ) ) # Lower cases the word\n",
    "  .reduceByKey( lambda a, b: a + b ) \n",
    " # Stores in a Tweet Object\n",
    "  .map( lambda rec: Candidato( rec[0], rec[1] ) )\n",
    " # Sorts Them in a dataframe\n",
    "  .foreachRDD( lambda rdd: rdd.toDF().sort( desc(\"count\") )\n",
    " # Registers only top 10 candidate to a table.\n",
    "  .limit(10).registerTempTable(\"c_monica\") ) )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just a tuple to assign names\n",
    "from collections import namedtuple\n",
    "\n",
    "fields = (\"candidato\", \"count\" )\n",
    "Candidato = namedtuple( 'Candidato', fields )\n",
    "\n",
    "# here we apply different operations on the tweets and save them to #a temporary sql table\n",
    "\n",
    "( lines.flatMap( lambda text: text.split( \" \" ) ) #Splits to a list\n",
    "  # Checks for    candidate calls  \n",
    "  .filter( lambda word: word.lower().startswith(\"iglesias\") ) \n",
    "  .map( lambda word: ( word.lower(), 1 ) ) # Lower cases the word\n",
    "  .reduceByKey( lambda a, b: a + b ) \n",
    " # Stores in a Tweet Object\n",
    "  .map( lambda rec: Candidato( rec[0], rec[1] ) )\n",
    " # Sorts Them in a dataframe\n",
    "  .foreachRDD( lambda rdd: rdd.toDF().sort( desc(\"count\") )\n",
    " # Registers only top 10 candidate to a table.\n",
    "  .limit(10).registerTempTable(\"c_iglesias\") ) )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just a tuple to assign names\n",
    "from collections import namedtuple\n",
    "\n",
    "fields = (\"candidato\", \"count\" )\n",
    "Candidato = namedtuple( 'Candidato', fields )\n",
    "\n",
    "# here we apply different operations on the tweets and save them to #a temporary sql table\n",
    "\n",
    "( lines.flatMap( lambda text: text.split( \" \" ) ) #Splits to a list\n",
    "  # Checks for    candidate calls  \n",
    "  .filter( lambda word: word.lower().startswith(\"edmundo\") ) \n",
    "  .map( lambda word: ( word.lower(), 1 ) ) # Lower cases the word\n",
    "  .reduceByKey( lambda a, b: a + b ) \n",
    " # Stores in a Tweet Object\n",
    "  .map( lambda rec: Candidato( rec[0], rec[1] ) )\n",
    " # Sorts Them in a dataframe\n",
    "  .foreachRDD( lambda rdd: rdd.toDF().sort( desc(\"count\") )\n",
    " # Registers only top 10 candidate to a table.\n",
    "  .limit(10).registerTempTable(\"c_edmundo\") ) )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just a tuple to assign names\n",
    "from collections import namedtuple\n",
    "\n",
    "fields = (\"candidato\", \"count\" )\n",
    "Candidato = namedtuple( 'Candidato', fields )\n",
    "\n",
    "# here we apply different operations on the tweets and save them to #a temporary sql table\n",
    "\n",
    "( lines.flatMap( lambda text: text.split( \" \" ) ) #Splits to a list\n",
    "  # Checks for    candidate calls  \n",
    "  .filter( lambda word: word.lower().startswith(\"monasterio\") ) \n",
    "  .map( lambda word: ( word.lower(), 1 ) ) # Lower cases the word\n",
    "  .reduceByKey( lambda a, b: a + b ) \n",
    " # Stores in a Tweet Object\n",
    "  .map( lambda rec: Candidato( rec[0], rec[1] ) )\n",
    " # Sorts Them in a dataframe\n",
    "  .foreachRDD( lambda rdd: rdd.toDF().sort( desc(\"count\") )\n",
    " # Registers only top 10 candidate to a table.\n",
    "  .limit(10).registerTempTable(\"c_monasterio\") ) )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the table structure\n",
    "from collections import namedtuple\n",
    "fields = (\"tag\", \"SA\" )\n",
    "Tweet = namedtuple( 'Tweet', fields )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "(lines.map( lambda text: Tweet( text, \"0\" ) ) # Stores in a Tweet Object\n",
    "    .foreachRDD( lambda rdd: rdd.toDF() # Sorts Them in a DF\n",
    "    .limit(20).registerTempTable(\"tweets\") ) # Registers to a table\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from IPython import display\n",
    "#import seaborn as sns\n",
    "import pandas\n",
    "\n",
    "import re\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to clean tweets for the SA\n",
    "import nltk\n",
    "#nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the TweetRead.py file at this point (in the other terminal windows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can run receive-Tweets.py and after that we can start streaming by running : ssc.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssc.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Google API Sheets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install google-api-python-client==1.6.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install gspread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install oauth2client "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the required libraries\n",
    "import gspread\n",
    "import pandas as pd\n",
    "from oauth2client.service_account import ServiceAccountCredentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the scope\n",
    "scope = ['https://spreadsheets.google.com/feeds','https://www.googleapis.com/auth/drive']\n",
    "\n",
    "# add credentials to the account\n",
    "creds = ServiceAccountCredentials.from_json_keyfile_name('madridelections2021.json', scope)\n",
    "\n",
    "# authorize the clientsheet \n",
    "client = gspread.authorize(creds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -----  Mentions ------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+\n",
      "|candidato|count|\n",
      "+---------+-----+\n",
      "|    ayuso|    4|\n",
      "|   ayuso.|    2|\n",
      "|   ayuso,|    1|\n",
      "+---------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sqlContext.sql(\"select * from c_ayuso\").show()\n",
    "df_cont = sqlContext.sql(\"select * from c_ayuso\")\n",
    "df_ay = df_cont.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+\n",
      "|   candidato|count|\n",
      "+------------+-----+\n",
      "|    iglesias|    5|\n",
      "| iglesias\"rt|    1|\n",
      "|iglesias.…rt|    1|\n",
      "|   iglesias,|    1|\n",
      "+------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sqlContext.sql(\"select * from c_iglesias\").show()\n",
    "df_cont = sqlContext.sql(\"select * from c_iglesias\")\n",
    "df_ig = df_cont.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+\n",
      "|   candidato|count|\n",
      "+------------+-----+\n",
      "|monasterio',|    1|\n",
      "+------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sqlContext.sql(\"select * from c_monasterio\").show()\n",
    "df_cont = sqlContext.sql(\"select * from c_monasterio\")\n",
    "df_ms = df_cont.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For now we will do only the 3 populars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sqlContext.sql(\"select * from c_edmundo\").show()\n",
    "#df_cont = sqlContext.sql(\"select * from c_edmundo\")\n",
    "#df_ed = df_cont.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sqlContext.sql(\"select * from c_monica\").show()\n",
    "#df_cont = sqlContext.sql(\"select * from c_monica\")\n",
    "#df_mo = df_cont.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sqlContext.sql(\"select * from c_gabilondo\").show()\n",
    "#df_cont = sqlContext.sql(\"select * from c_gabilondo\")\n",
    "#df_ga = df_cont.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# append all the 6 DF\n",
    "#df_menciones = pd.concat([df_ay, df_ig, df_ga, df_mo, df_ms, df_ed]).drop_duplicates(subset=['candidato'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can append the df and collect in one candidate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# append all the 3 DF\n",
    "df_menciones = pd.concat([df_ay, df_ig, df_ms]).drop_duplicates(subset=['candidato'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_menciones.candidato = df_menciones.candidato.apply(lambda x: 'ISABEL DIAZ AYUSO' if 'ayuso' in x else x)\n",
    "df_menciones.candidato = df_menciones.candidato.apply(lambda x: 'PABLO IGLESIAS' if 'iglesias' in x else x)\n",
    "df_menciones.candidato = df_menciones.candidato.apply(lambda x: 'ROCIO MONASTERIO' if 'monasterio' in x else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>candidato</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ISABEL DIAZ AYUSO</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ISABEL DIAZ AYUSO</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ISABEL DIAZ AYUSO</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PABLO IGLESIAS</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PABLO IGLESIAS</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PABLO IGLESIAS</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PABLO IGLESIAS</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ROCIO MONASTERIO</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           candidato  count\n",
       "0  ISABEL DIAZ AYUSO      4\n",
       "1  ISABEL DIAZ AYUSO      2\n",
       "2  ISABEL DIAZ AYUSO      1\n",
       "0     PABLO IGLESIAS      5\n",
       "1     PABLO IGLESIAS      1\n",
       "2     PABLO IGLESIAS      1\n",
       "3     PABLO IGLESIAS      1\n",
       "0   ROCIO MONASTERIO      1"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_menciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mentions to Google Sheet LIVE!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the instance of the Spreadsheet\n",
    "sheet = client.open('STREAMING-MENTIONS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lote ----->  1\n",
      "Lote ----->  2\n",
      "Lote ----->  3\n",
      "Lote ----->  4\n",
      "Lote ----->  5\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "df_ant = df_menciones\n",
    "\n",
    "#insert the first query\n",
    "sheet_instance = sheet.get_worksheet(0)\n",
    "sheet_instance.insert_rows(df_menciones.values.tolist(), row = 2)\n",
    "\n",
    "while count < 5:\n",
    "    print(\"Lote -----> \" , count + 1)\n",
    "    time.sleep( 3 )\n",
    "    \n",
    "    ##-----------------Create DF_Mentions----------------------##\n",
    "    df_cont = sqlContext.sql(\"select * from c_ayuso\")\n",
    "    df_ay = df_cont.toPandas()\n",
    "\n",
    "    df_cont = sqlContext.sql(\"select * from c_monasterio\")\n",
    "    df_ms = df_cont.toPandas()\n",
    "\n",
    "    df_cont = sqlContext.sql(\"select * from c_iglesias\")\n",
    "    df_ig = df_cont.toPandas()\n",
    "\n",
    "    # append all the 3 DF\n",
    "    df_menciones = pd.concat([df_ay, df_ig, df_ms]).drop_duplicates(subset=['candidato'])\n",
    "\n",
    "    df_menciones.candidato = df_menciones.candidato.apply(lambda x: 'ISABEL DIAZ AYUSO' if 'ayuso' in x else x)\n",
    "    df_menciones.candidato = df_menciones.candidato.apply(lambda x: 'PABLO IGLESIAS' if 'iglesias' in x else x)\n",
    "    df_menciones.candidato = df_menciones.candidato.apply(lambda x: 'ROCIO MONASTERIO' if 'monasterio' in x else x)\n",
    "    #-----------------END Create DF_Mentions----------------------##\n",
    "    \n",
    "    \n",
    "    if not(df_ant.equals(df_menciones)):\n",
    "        # get the first sheet of the Spreadsheet (SA)\n",
    "        sheet_instance = sheet.get_worksheet(0)\n",
    "        sheet_instance.insert_rows(df_menciones.values.tolist(), row = 2)\n",
    "    \n",
    "    df_ant = df_menciones\n",
    "    count = count + 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ---- SA ---- Twitts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the instance of the Spreadsheet\n",
    "sheet = client.open('SA-Candidates')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---+\n",
      "|                 tag| SA|\n",
      "+--------------------+---+\n",
      "|Por…@PabloEcheniq...|  0|\n",
      "|#GobiernoDimision...|  0|\n",
      "|No saben q…@elmun...|  0|\n",
      "|A ver si esto les...|  0|\n",
      "|                    |  0|\n",
      "|Defienden modific...|  0|\n",
      "|                    |  0|\n",
      "|Por…RT @Tonicanto...|  0|\n",
      "|                    |  0|\n",
      "|Por…RT @Accountab...|  0|\n",
      "|                    |  0|\n",
      "|-Cloacas contra P...|  0|\n",
      "|-Lezo y otras cor...|  0|\n",
      "|  -Cohecho con Ayuso|  0|\n",
      "|-Manipulación co…...|  0|\n",
      "|Verg… https://t.c...|  0|\n",
      "|\"SÍ SE PUEDE. QUE...|  0|\n",
      "+--------------------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sqlContext.sql(\"select * from tweets\").show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's define a procedure to clean the tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text(raw_text):\n",
    "    letters_only = re.sub(\"[^A-zÀ-ú]\", \" \",str(raw_text)) \n",
    "    #print(letters_only)\n",
    "    letters_only = re.sub(\"([HhJj][A-zÀ-ú]){2,}[HhJj]*\", \"jajaja\", str(letters_only))\n",
    "    words = letters_only.lower().split()\n",
    "    #print(words)\n",
    "    stops = set(stopwords.words(\"spanish\"))  \n",
    "    not_stop_words = [w for w in words if not w in stops]\n",
    "    return (\" \".join(not_stop_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can enter in a loop and it will be calculating the SA real-time, getting the tweets from the TABLE SQL \n",
    "that is calculated/produced above - Let's start with 20 - it can be infinite and the dashboard gets constant updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lote ----->  1\n",
      " * Tweet *  -  Por…@PabloEchenique Deberías preguntarte cuántos Podemonguers habría disfrutando del botellón después de haber criticad… https://t.co/1ekZJCBVYXRT @Tonicanto1: El socialismo es que Begoña Gómez -que dirige una cátedra extraordinaria de Transformación Social, sin ser catedrática ni t…RT @cincinatoss: Saben lo que viene, como Pablo Iglesias, y huyen de la quema. \n",
      "The sentiment --->  NEG \n",
      "\n",
      " * Tweet *  -  #GobiernoDimisionRT @Cazatalentos: La cara de orgasmo de Ferreras y compañía con la renuncia de Pablo Iglesias se les hacía parecer muy felices. \n",
      "The sentiment --->  NEG \n",
      "\n",
      " * Tweet *  -  No saben q…@elmundoes Entiendo q como además Biden está copiando sus “ políticas” en USA, en breves tb culparán a Ayuso del asesinato de KennedyRT @cat_nordic: (4/5) A Madrid, però, la ultra-dreta està desbocada i per això la judicatura li va fotre enlaire ahir, al “guapito de cara”…RT @LeonelFernandez: #MartesDeLectura: ¿Es correcto calificar de populista a figuras tan disímiles como Hugo Chávez, Donald Trump, Marine L…RT @romaochaita: Como diría el gran Eugenio.. Se saben aquel que diu... un pobre menesteroso en Madrid encontrase una lampara maravillosa y…RT @PSOE: Por fin han tenido una victoria electoral...bueno, ustedes no, Ayuso.\n",
      "The sentiment --->  NEG \n",
      "\n",
      " * Tweet *  -  A ver si esto les tranquiliza...\n",
      "The sentiment --->  NEU \n",
      "\n",
      " * Tweet *  -  Defienden modificaciones…El Gobierno afirma que los malos datos covid de Madrid han perjudicado a España ante el Reino Unido https://t.co/ErMuxsUvGPRT @And89_3: Pablo Iglesias peleó la subida del SMI, el IMV o la subida de las pensiones y tú le odias, Ana Botella vendió viviendas públic…RT @Jakimuca: ¿Por qué Ana Rosa Quintana arremete contra Podemos y Pablo Iglesias? https://t.co/BDUzNDgQuNRT @Tonicanto1: El socialismo es que Begoña Gómez -que dirige una cátedra extraordinaria de Transformación Social, sin ser catedrática ni t…Ayuso contra la OCDE, contra la decencia y contra la población en general. Eso sí, defendiendo al 1% más rico con t… https://t.co/V241cS1K7lRT @pablocast13: Dice la ministra de Exteriores que la culpa de que Reino Unido recomiende no viajar a España este verano es de Ayuso.\n",
      "The sentiment --->  NEG \n",
      "\n",
      " * Tweet *  -  Por…RT @Tonicanto1: El socialismo es que Begoña Gómez -que dirige una cátedra extraordinaria de Transformación Social, sin ser catedrática ni t…RT @AntonioRNaranjo: Tienen que ver el manojo de sopapos a mano abierta que esta periodista americana da a Pedro Sánchez y Pablo Iglesias.…RT @pablocast13: Dice la ministra de Exteriores que la culpa de que Reino Unido recomiende no viajar a España este verano es de Ayuso.\n",
      "The sentiment --->  NEG \n",
      "\n",
      " * Tweet *  -  Por…RT @Accountable2019: Atresmedia:\n",
      "The sentiment --->  NEU \n",
      "\n",
      " * Tweet *  -  -Cloacas contra Podemos e independentistas\n",
      "The sentiment --->  NEU \n",
      "\n",
      " * Tweet *  -  -Lezo y otras corrupciones\n",
      "The sentiment --->  NEG \n",
      "\n",
      " * Tweet *  -  -Cohecho con Ayuso\n",
      "The sentiment --->  NEG \n",
      "\n",
      " * Tweet *  -  -Manipulación co…@ACOM_es @Tonicanto1 GONZÁLEZ LAYA: \"LA IRRESPONSABILIDAD DE MADRID HA PERJUDICADO A ESPAÑA EN EL REINO UNIDO\"\n",
      "The sentiment --->  NEG \n",
      "\n",
      " * Tweet *  -  Verg… https://t.co/hrr0mwadFIRT @ProLibertate19: \"Ayuso como exemplo para a salvação de Sánchez\" por @pedromdsa1 https://t.co/of8HY3PBclRT @pedroagbilbao: Atentos: hace unos tuíts expuse el temor de que PPSOE maniobran para quitarse socios, restablecer el bipartidismo inclus…@romaochaita Ayuso hace mucho daño con \"su\" libertad (libertinaje) a los sanitarios de toda España. Un saludo afectuoso. Sé felizRT @gabriellaperu: Pablo Iglesias no viene a apoyar a Castillo, sino a promover las movilizaciones, incendios, tomas de carretera y desmane…RT @pablom_m: Solo vengo para decir que la fiscalía anticorrupción asegura que Rodrigo Rato ocultó 77 millones de euros en una sociedad de…RT @TabarniaB: Este fue el último tuit de Pablo Iglesias, hace 8 días. \n",
      "The sentiment --->  NEG \n",
      "\n",
      " * Tweet *  -  \"SÍ SE PUEDE. QUE HABLE LA MAYORÍA\" decía... \n",
      "The sentiment --->  NEU \n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1_content = sqlContext.sql( 'Select tag, SA from tweets' )\n",
    "df1 = df1_content.toPandas()\n",
    "\n",
    "    \n",
    "count = 0\n",
    "\n",
    "while count < 1:\n",
    "    print(\"Lote -----> \" , count + 1)\n",
    "    time.sleep( 3 )\n",
    "    df2_content = sqlContext.sql( 'Select tag, SA from tweets' )\n",
    "    df2 = df2_content.toPandas()\n",
    "    \n",
    "    # Concatenating dataframes without duplicates\n",
    "    df_tweets = pd.concat([df1, df2]).drop_duplicates(subset=['tag'])\n",
    "    df_tweets = df_tweets[df_tweets['tag'].apply(len)>10]\n",
    "\n",
    "    df_tweets['SA'] = \"\"\n",
    "    i = 0\n",
    "    \n",
    "    for i, row in df_tweets.iterrows():\n",
    "        print(\" * Tweet *  - \" , df_tweets[\"tag\"][i])\n",
    "        twit = df_tweets[\"tag\"][i]\n",
    "        twit = process_text(twit)\n",
    "        sa = analyzer.predict(twit)\n",
    "        df_tweets.at[i,'SA'] = sa\n",
    "        print(\"The sentiment ---> \", sa, \"\\n\")\n",
    "    \n",
    "    df=df_tweets.copy()\n",
    "    sheet_instance = sheet.get_worksheet(0)\n",
    "    sheet_instance.insert_rows(df.values.tolist(), row = 2)\n",
    "    count = count + 1\n",
    "\n",
    "    # get the first sheet of the Spreadsheet (SA)\n",
    "\n",
    "\n",
    "    df1 = df_tweets.copy()\n",
    "    df1['SA'] = \"0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inside the loop we have the DF (df_tweets) that is being calculated.\n",
    "## At the end of the loop, we will have the last DF with the SA to be published in Tablaeu\n",
    "## This will be refreshed everytime that we run the LOOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df=df_tweets.copy()\n",
    "#sheet_instance = sheet.get_worksheet(0)\n",
    "#sheet_instance.insert_rows(df.values.tolist(), row = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets = df_tweets.sort_values(by=['tag'])\n",
    "df_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssc.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thanks!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
